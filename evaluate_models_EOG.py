# evaluate_models.py
# åŠŸèƒ½ï¼šåŠ è½½è®­ç»ƒå¥½çš„ .h5 æ¨¡å‹æ–‡ä»¶ï¼Œé‡æ–°è¯„ä¼°å¹¶è¾“å‡ºå¤šç§æ€§èƒ½æŒ‡æ ‡

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from scipy.stats import pearsonr
from skimage.metrics import structural_similarity as ssim
import os
import matplotlib.pyplot as plt
import math
from train_EOG import BasicBlockall



# ========== æ•°æ®é¢„å¤„ç†æ¨¡å— ==========

def get_rms(records):
    return math.sqrt(sum([x ** 2 for x in records]) / len(records))

def random_signal(signal, combin_num):
    random_result = []
    for i in range(combin_num):
        random_num = np.random.permutation(signal.shape[0])
        shuffled_dataset = signal[random_num, :]
        shuffled_dataset = shuffled_dataset.reshape(signal.shape[0], signal.shape[1])
        random_result.append(shuffled_dataset)
    return np.array(random_result)

def prepare_data(EEG_all, noise_all, combin_num, train_per):
    EEG_all_random = np.squeeze(random_signal(signal=EEG_all, combin_num=1))
    noise_all_random = np.squeeze(random_signal(signal=noise_all, combin_num=1))

    # åªä¿ç•™ä¸å™ªå£°æ•°æ®ç­‰é•¿çš„ EEG æ•°æ®
    EEG_all_random = EEG_all_random[0:noise_all_random.shape[0]]

    timepoint = noise_all_random.shape[1]
    train_num = round(train_per * EEG_all_random.shape[0])
    validation_num = round((EEG_all_random.shape[0] - train_num) / 2)
    test_num = EEG_all_random.shape[0] - train_num - validation_num

    train_eeg = EEG_all_random[0:train_num, :]
    validation_eeg = EEG_all_random[train_num:train_num + validation_num, :]
    test_eeg = EEG_all_random[train_num + validation_num:EEG_all_random.shape[0], :]

    train_noise = noise_all_random[0:train_num, :]
    validation_noise = noise_all_random[train_num:train_num + validation_num, :]
    test_noise = noise_all_random[train_num + validation_num:noise_all_random.shape[0], :]

    EEG_test = []
    noise_EEG_test = []
    for j in range(test_eeg.shape[0]):
        eeg = test_eeg[j]
        noise = test_noise[j]
        coe = get_rms(eeg) / (get_rms(noise) * 1.0)  # å›ºå®š SNR = 1
        noise = noise * coe
        neeg = noise + eeg
        noise_EEG_test.append(neeg)
        EEG_test.append(eeg)

    noise_EEG_test = np.array(noise_EEG_test)
    EEG_test = np.array(EEG_test)

    # æ ‡å‡†åŒ–
    EEG_test_end_standard = EEG_test / np.std(noise_EEG_test, axis=1, keepdims=True)
    noiseEEG_test_end_standard = noise_EEG_test / np.std(noise_EEG_test, axis=1, keepdims=True)

    return noiseEEG_test_end_standard, EEG_test_end_standard


# ========== æ€§èƒ½æŒ‡æ ‡è®¡ç®—å‡½æ•° ==========

def calculate_mse(clean, denoised):
    """å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰"""
    if len(clean.shape) == 3:
        clean = np.squeeze(clean, axis=-1)
    if len(denoised.shape) == 3:
        denoised = np.squeeze(denoised, axis=-1)
    return np.mean((clean - denoised) ** 2)


def calculate_mae(clean, denoised):
    """å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰"""
    if len(clean.shape) == 3:
        clean = np.squeeze(clean, axis=-1)
    if len(denoised.shape) == 3:
        denoised = np.squeeze(denoised, axis=-1)
    return np.mean(np.abs(clean - denoised))


def calculate_snr(clean, denoised):
    """ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰"""
    if len(clean.shape) == 3:
        clean = np.squeeze(clean, axis=-1)
    if len(denoised.shape) == 3:
        denoised = np.squeeze(denoised, axis=-1)
    noise = clean - denoised
    snr = 10 * np.log10(np.var(clean) / np.var(noise))
    return snr


def calculate_snr_improvement(clean, noisy, denoised):
    """å»å™ªå‰å SNR æå‡"""
    input_snr = calculate_snr(clean, noisy)
    output_snr = calculate_snr(clean, denoised)
    return output_snr - input_snr


def calculate_pearson(clean, denoised):
    """çš®å°”é€Šç›¸å…³ç³»æ•°ï¼ˆæ³¢å½¢ä¸€è‡´æ€§ï¼‰"""
    if len(clean.shape) == 3:
        clean = np.squeeze(clean, axis=-1)
    if len(denoised.shape) == 3:
        denoised = np.squeeze(denoised, axis=-1)

    correlations = []
    for i in range(clean.shape[0]):
        try:
            corr, _ = pearsonr(clean[i], denoised[i])
            correlations.append(corr)
        except:
            continue
    return np.nanmean(correlations)


def waveform_fidelity(clean, denoised):
    """æ³¢å½¢ä¿çœŸåº¦ï¼ˆä½¿ç”¨ç›¸å…³ç³»æ•°ï¼‰"""
    if len(clean.shape) == 3:
        clean = np.squeeze(clean, axis=-1)
    if len(denoised.shape) == 3:
        denoised = np.squeeze(denoised, axis=-1)

    fidelity = []
    for i in range(clean.shape[0]):
        try:
            wf = np.corrcoef(clean[i], denoised[i])[0, 1]
            fidelity.append(wf)
        except:
            continue
    return np.nanmean(fidelity)


def calculate_ssim_score(clean, denoised):
    """ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ ‡ï¼ˆSSIMï¼‰ï¼Œé€‚ç”¨äºä¸€ç»´ä¿¡å·"""
    if len(clean.shape) == 3:
        clean = np.squeeze(clean, axis=-1)
    if len(denoised.shape) == 3:
        denoised = np.squeeze(denoised, axis=-1)

    scores = []
    for i in range(clean.shape[0]):
        try:
            score = ssim(clean[i], denoised[i], win_size=64)
            scores.append(score)
        except:
            continue
    return np.nanmean(scores)


# ========== ä¸»ç¨‹åº ==========

if __name__ == "__main__":
    all_predictions = {}  # æ–°å¢ï¼šç”¨äºä¿å­˜æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ

    # è·¯å¾„è®¾ç½®
    result_dir = "results_EOG"
    file_location = r"D:\EEGdenoiseNet-master\EEGdenoiseNet-master\data\\"

    # åŠ è½½å¹²å‡€å’Œå¸¦å™ªå£°çš„æµ‹è¯•æ•°æ®
    EEG_all = np.load(file_location + "EEG_all_epochs.npy")
    noise_all = np.load(file_location + "EOG_all_epochs.npy")

    # å‡†å¤‡æµ‹è¯•é›†ï¼ˆæ ‡å‡†åŒ–åçš„å™ªå£° EEG å’Œ Clean EEGï¼‰
    X_test, y_test = prepare_data(EEG_all, noise_all, combin_num=10, train_per=0.8)

    # æ‰©å±•ç»´åº¦ä»¥é€‚é… CNN è¾“å…¥ [batch, time] -> [batch, time, 1]
    X_test_cnn = np.expand_dims(X_test, axis=-1)

    # æ¨¡å‹è·¯å¾„
    model_paths = {
        "fcNN": os.path.join(result_dir, "fcNN_best.h5"),
        "Simple_CNN": os.path.join(result_dir, "Simple_CNN_best.h5"),
        "Complex_CNN": os.path.join(result_dir, "Complex_CNN_best.h5"),
    }

    all_metrics = {}

    # é€ä¸ªåŠ è½½æ¨¡å‹å¹¶è¯„ä¼°
    for name, path in model_paths.items():
        print(f"\nğŸ”„ åŠ è½½å¹¶è¯„ä¼°æ¨¡å‹: {name}")
        # æ³¨å†Œè‡ªå®šä¹‰å±‚
        from tensorflow.keras.utils import get_custom_objects

        get_custom_objects().update({'BasicBlockall': BasicBlockall})  # æ›¿æ¢ä¸ºä½ å®é™…çš„ç±»å
        model = load_model(path, compile=False)

        # è·å–é¢„æµ‹ç»“æœ
        pred = model.predict(X_test_cnn)  # è¾“å‡ºä¸º [batch, time, 1]
        pred = np.squeeze(pred)  # å»æ‰ channel ç»´åº¦ [batch, time]
        all_predictions[name] = pred  # ä¿å­˜å½“å‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ

        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        metrics = {
            "MSE": calculate_mse(y_test, pred),
            "MAE": calculate_mae(y_test, pred),
            "SNR": calculate_snr(y_test, pred),
            "SNR Improvement": calculate_snr_improvement(y_test, X_test, pred),  # éœ€è¦åŸå§‹å™ªå£° EEG
            "Pearson": calculate_pearson(y_test, pred),
            "Waveform_Fidelity": waveform_fidelity(y_test, pred),
            "SSIM": calculate_ssim_score(y_test, pred)
        }

        all_metrics[name] = metrics

        # æ‰“å°ç»“æœ
        print(f"{name} æ€§èƒ½æŒ‡æ ‡:")
        for metric_name, value in metrics.items():
            print(f"  {metric_name}: {value:.4f}")

    # å¯è§†åŒ–ä¸€ä¸ªæ ·æœ¬çš„ç»“æœ
    def plot_comparison(original, noisy, denoised, idx=0):
        plt.figure(figsize=(14, 4))
        plt.plot(original[idx], label='Clean EEG')
        plt.plot(noisy[idx], label='Noisy EEG')
        plt.plot(denoised[idx], label='Denoised EEG')
        plt.title(f"Signal Comparison (Index {idx}) - {name}")
        plt.xlabel("Time Points")
        plt.ylabel("Amplitude")
        plt.legend()
        plt.grid(True)
        plt.show()

    # ç¤ºä¾‹å¯è§†åŒ–
    for name, res in all_metrics.items():
        idx = 0  # å¯ä»¥æ›´æ¢ç´¢å¼•æŸ¥çœ‹ä¸åŒæ ·æœ¬
        pred = all_predictions[name]  # å–å‡ºè¯¥æ¨¡å‹è‡ªå·±çš„é¢„æµ‹ç»“æœ
        plot_comparison(y_test, X_test, pred, idx = idx)

    # ä¿å­˜æŒ‡æ ‡åˆ° JSON æ–‡ä»¶
    import json
    with open(os.path.join(result_dir, "final_metrics.json"), "w") as f:
        json.dump({k: {mk: float(mv) for mk, mv in v.items()} for k, v in all_metrics.items()}, f, indent=4)

    print("\nğŸ“Š æŒ‡æ ‡å·²ä¿å­˜è‡³ final_metrics.json")
